{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gZKq_8MGDqp"
      },
      "source": [
        "# Source code: https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\r\n",
        "# Additional list of ML methods:\r\n",
        "## https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/\r\n",
        "## https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\r\n",
        "\r\n",
        "\r\n",
        "# Compare algorithms\r\n",
        "from pandas import read_csv\r\n",
        "from matplotlib import pyplot\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "from sklearn.ensemble import AdaBoostClassifier\r\n",
        "from sklearn.linear_model import SGDClassifier\r\n",
        "from sklearn.neural_network import MLPClassifier\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "random_value = 1\r\n",
        "\r\n",
        "# Load dataset\r\n",
        "file = \"https://raw.githubusercontent.com/ivanksinggih/Intel_minifab_Anylogic/data/final_data_values.csv\"\r\n",
        "data_title = ['total_captures_queue_A_per_week', 'total_captures_queue_B_per_week', 'total_captures_queue_C_per_week', 'total_captures_queue_D_per_week', 'total_captures_queue_E_per_week', 'total_captures_queue_AB_per_week', 'total_captures_queue_CD_per_week', 'total_captures_queue_A_1_per_week', 'total_captures_queue_A_5_per_week', 'total_captures_queue_B_1_per_week', 'total_captures_queue_B_5_per_week', 'total_captures_queue_C_2_per_week', 'total_captures_queue_C_4_per_week', 'total_captures_queue_D_2_per_week', 'total_captures_queue_D_4_per_week', 'total_captures_queue_E_3_per_week', 'total_captures_queue_E_6_per_week', 'machine_A_step1_per_week', 'machine_A_step5_per_week', 'machine_B_step1_per_week', 'machine_B_step5_per_week', 'machine_C_step2_per_week', 'machine_C_step4_per_week', 'machine_D_step2_per_week', 'machine_D_step4_per_week', 'machine_E_step3_per_week', 'machine_E_step6_per_week', 'machine_A_available_production_time_with_idle per week', 'machine_B_available_production_time_with_idle per week', 'machine_C_available_production_time_with_idle per week', 'machine_D_available_production_time_with_idle per week', 'machine_E_available_production_time_with_idle per week', 'machine_A_utilization_all_working_times per week', 'machine_B_utilization_all_working_times per week', 'machine_C_utilization_all_working_times per week', 'machine_D_utilization_all_working_times per week', 'machine_E_utilization_all_working_times per week', 'machine_A_idle_time_percentage per week', 'machine_B_idle_time_percentage per week', 'machine_C_idle_time_percentage per week', 'machine_D_idle_time_percentage per week', 'machine_E_idle_time_percentage per week', 'throughput_per_week']\r\n",
        "\r\n",
        "dataset = read_csv(file, names=data_title)\r\n",
        "\r\n",
        "# Split-out validation dataset\r\n",
        "array = dataset.values\r\n",
        "X = array[:,0:len(data_title)-1]\r\n",
        "y = array[:,len(data_title)-1]\r\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=random_value)\r\n",
        "\r\n",
        "# Spot Check Algorithms\r\n",
        "models = []\r\n",
        "models.append(('AB', AdaBoostClassifier()))\r\n",
        "models.append(('SGD', SGDClassifier(random_state=random_value, shuffle=True)))\r\n",
        "models.append(('NNMLP', MLPClassifier(alpha=1, max_iter=1000, random_state=random_value, shuffle=True)))\r\n",
        "models.append(('GB', GradientBoostingClassifier(random_state=random_value)))\r\n",
        "models.append(('RF', RandomForestClassifier(random_state=random_value)))\r\n",
        "models.append(('KNN', KNeighborsClassifier()))\r\n",
        "models.append(('CART', DecisionTreeClassifier(random_state=random_value)))\r\n",
        "models.append(('NB', GaussianNB()))\r\n",
        "models.append(('SVM', SVC(gamma='auto', random_state=random_value)))\r\n",
        "# evaluate each model in turn\r\n",
        "results = []\r\n",
        "names = []\r\n",
        "selectedName = \"\";\r\n",
        "selectedModel = \"\";\r\n",
        "largestAccuracy = 0;\r\n",
        "kfold = StratifiedKFold(n_splits=10, random_state=random_value, shuffle=True)\r\n",
        "for name, model in models:\r\n",
        "\trandom_seed = random.seed(random_value)\r\n",
        "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\r\n",
        "\toptimized_parameters = model.get_params(deep=True)\r\n",
        "\tresults.append(cv_results)\r\n",
        "\tnames.append(name)\r\n",
        "\tif (cv_results.mean() > largestAccuracy):\r\n",
        "\t\tlargestAccuracy = cv_results.mean();\r\n",
        "\t\tselectedName = name;\r\n",
        "\t\tselectedModel = model;\r\n",
        "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\r\n",
        "\t# print('optimized_parameters',optimized_parameters)\r\n",
        "\tprint()\r\n",
        "# Compare Algorithms\r\n",
        "pyplot.boxplot(results, labels=names)\r\n",
        "pyplot.show()\r\n",
        "\r\n",
        "\r\n",
        "n = len(data_title)-1;\r\n",
        "currentlargestAccuracy_perReducedSize = largestAccuracy;\r\n",
        "current_combinations_removedColumnIndex_Sets = list();\r\n",
        "current_X_train = X_train.copy();\r\n",
        "bestlargestAccuracy_perReducedSize = largestAccuracy;\r\n",
        "best_combinations_removedColumnIndex_Sets = list();\r\n",
        "best_X_train = X_train.copy();\r\n",
        "initial_column_index = list(range(0,len(data_title)-1))\r\n",
        "r = 1;\r\n",
        "copy_of_data_title = data_title.copy();\r\n",
        "for iteration in range(1, len(data_title)-1):\r\n",
        "\r\n",
        "\tlargestAccuracy_sameReducedSize = 0;\r\n",
        "\tselectedSet_combinations_removedColumnIndex = list();\r\n",
        "\t\r\n",
        "\t# find combinations in a set (n_C_r)\r\n",
        "\t# start with the next largest number of input parameters = n-1\r\n",
        "\t# (if a better accuracy is obtained, then reduce the number of input parameters (from the current best combination), until the accuracy is not improved anymore, etc)\r\n",
        "\t# source code: https://www.baeldung.com/java-combinations-algorithm\r\n",
        "\t\r\n",
        "\tcombinations_removedColumnIndex_Sets = list();\r\n",
        "\tcombination = [None] * r\r\n",
        "    # initialize with lowest lexicographic combination\r\n",
        "\tfor i in range(0, r):\r\n",
        "\t\tcombination[i] = i;\r\n",
        "\t\r\n",
        "\twhile combination[r-1] < n:\r\n",
        "\t\tcombinations_removedColumnIndex_Sets += [combination.copy()]\r\n",
        "\t\t\r\n",
        "\t\t# generate next combination in lexicographic order\r\n",
        "\t\tt = r - 1;\r\n",
        "\t\twhile t != 0 and combination[t] == n - r + t:\r\n",
        "\t\t\tt -= 1;\r\n",
        "\t\tcombination[t] += 1;\r\n",
        "\t\tfor i in range(t+1, r):\r\n",
        "\t\t\tcombination[i] = combination[i-1] + 1;\r\n",
        "\t\r\n",
        "\tkfold = StratifiedKFold(n_splits=10, random_state=random_value, shuffle=True)\r\n",
        "\tfor i in range(0, len(combinations_removedColumnIndex_Sets)):\r\n",
        "\r\n",
        "\t\trandom_seed = random.seed(random_value);\r\n",
        "\r\n",
        "\t\tprint(\"i = \", i, \"; len(combinations_removedColumnIndex_Sets) = \", len(combinations_removedColumnIndex_Sets));\r\n",
        "\t\treduced_X_train = current_X_train.copy()\r\n",
        "\t\treduced_X_train = np.delete(reduced_X_train,combinations_removedColumnIndex_Sets[i][0],1);\r\n",
        "\r\n",
        "\t\t# Retest accuracy with the reduced data\r\n",
        "\t\tcv_results = cross_val_score(model, reduced_X_train, Y_train, cv=kfold, scoring='accuracy')\r\n",
        "\t\toptimized_parameters = model.get_params(deep=True)\r\n",
        "\t\tresults.append(cv_results)\r\n",
        "\t\tnames.append(name)\r\n",
        "\t\tif (cv_results.mean() > largestAccuracy_sameReducedSize):\r\n",
        "\t\t\tlargestAccuracy_sameReducedSize = cv_results.mean();\r\n",
        "\t\t\tselectedSet_combinations_removedColumnIndex = i;\r\n",
        "\r\n",
        "\tcurrentlargestAccuracy_perReducedSize = largestAccuracy_sameReducedSize;\r\n",
        "\tcurrent_X_train = np.delete(current_X_train,combinations_removedColumnIndex_Sets[selectedSet_combinations_removedColumnIndex][0],1);\r\n",
        "\tcurrent_combinations_removedColumnIndex_Sets += [initial_column_index[combinations_removedColumnIndex_Sets[selectedSet_combinations_removedColumnIndex][0]]];\r\n",
        "\tdel initial_column_index[combinations_removedColumnIndex_Sets[selectedSet_combinations_removedColumnIndex][0]];\r\n",
        "\tdel copy_of_data_title[combinations_removedColumnIndex_Sets[selectedSet_combinations_removedColumnIndex][0]];\r\n",
        "\tprint(\"currentlargestAccuracy_perReducedSize, data_title: \", currentlargestAccuracy_perReducedSize, \"; \", copy_of_data_title, \"(\", initial_column_index, \")\");\r\n",
        "\tn -= 1;\r\n",
        "\r\n",
        "\tif largestAccuracy_sameReducedSize >= bestlargestAccuracy_perReducedSize:\r\n",
        "\t\tbestlargestAccuracy_perReducedSize = currentlargestAccuracy_perReducedSize;\r\n",
        "\t\tbest_X_train = current_X_train.copy();\r\n",
        "\t\tbest_combinations_removedColumnIndex_Sets = current_combinations_removedColumnIndex_Sets.copy();\r\n",
        "\t\tdata_title = copy_of_data_title.copy();\r\n",
        "\r\n",
        "# Obtain input data combination with the best accuracy\r\n",
        "best_combinations_removedColumnIndex_Sets.sort();\r\n",
        "X_train = best_X_train.copy()\r\n",
        "for j in range(len(best_combinations_removedColumnIndex_Sets)-1,-1,-1):\r\n",
        "\tX_validation = np.delete(X_validation,best_combinations_removedColumnIndex_Sets[j],1);\r\n",
        "\r\n",
        "# Retrain model (using important input data)\r\n",
        "kfold = StratifiedKFold(n_splits=10, random_state=random_value, shuffle=True);\r\n",
        "cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy');\r\n",
        "optimized_parameters = model.get_params(deep=True);\r\n",
        "results.append(cv_results);\r\n",
        "names.append(name);\r\n",
        "print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()));\r\n",
        "print();\r\n",
        "\r\n",
        "print(\"data_title:\");\r\n",
        "print(data_title);\r\n",
        "print();\r\n",
        "\r\n",
        "print()\r\n",
        "print('Prediction step')\r\n",
        "# Make predictions on validation dataset\r\n",
        "print()\r\n",
        "print('selectedName = ',selectedName)\r\n",
        "selectedModel.fit(X_train, Y_train)\r\n",
        "predictions = selectedModel.predict(X_validation)\r\n",
        "# Evaluate predictions\r\n",
        "print(accuracy_score(Y_validation, predictions))\r\n",
        "print(confusion_matrix(Y_validation, predictions))\r\n",
        "print(classification_report(Y_validation, predictions))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
